{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Udacity's SDCND\n",
    "\n",
    "### Vehicle Detection and Tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, My goal is to write a software pipeline to identify vehicles in a video from a front-facing camera on a car. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import cv2\n",
    "import glob\n",
    "import time\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "from skimage.feature import hog\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "from sklearn.model_selection import train_test_split\n",
    "# https://docs.scipy.org/doc/scipy-0.16.0/reference/generated/scipy.ndimage.measurements.label.html\n",
    "from scipy.ndimage.measurements import label\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "print('START')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section I: Camera Calibration and Distortion Correction\n",
    "\n",
    "##### Compute the camera calibration matrix and distortion coefficients given a set of chessboard images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "objp = np.zeros((6*9,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2)\n",
    "\n",
    "objpoints = []\n",
    "imgpoints = []\n",
    "\n",
    "images = glob.glob('resources/camera_cal/calibration*.jpg')\n",
    "\n",
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (9,6), None)\n",
    "\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)\n",
    "\n",
    "        img = cv2.drawChessboardCorners(img, (9,6), corners, ret)\n",
    "        \n",
    "        #cv2.imshow('img', img)\n",
    "        #cv2.waitKey(500)\n",
    "\n",
    "#cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Apply a distortion correction to raw images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('resources/camera_cal/calibration2.jpg')\n",
    "img_size = (img.shape[1], img.shape[0])\n",
    "\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img_size, None, None)\n",
    "\n",
    "dst = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "cv2.imwrite('resources/camera_cal/test_undist.jpg',dst)\n",
    "\n",
    "dist_pickle = {}\n",
    "dist_pickle[\"mtx\"] = mtx\n",
    "dist_pickle[\"dist\"] = dist\n",
    "pickle.dump(dist_pickle, open(\"resources/camera_cal/dist_pickle.p\", \"wb\"));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Unwarp corners and visualize resulting images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dist_pickle = pickle.load( open( \"resources/camera_cal/dist_pickle.p\", \"rb\" ) )\n",
    "mtx = dist_pickle[\"mtx\"]\n",
    "dist = dist_pickle[\"dist\"]\n",
    "img = cv2.imread('resources/camera_cal/calibration2.jpg')\n",
    "nx = 8\n",
    "ny = 6\n",
    "def corners_unwarp(img, nx=nx, ny=ny, mtx=mtx, dist=dist):\n",
    "    undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    gray = cv2.cvtColor(undist, cv2.COLOR_BGR2GRAY)\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (nx, ny), None)\n",
    "    if ret == True:\n",
    "        cv2.drawChessboardCorners(undist, (nx, ny), corners, ret)\n",
    "        offset = 100\n",
    "        img_size = (gray.shape[1], gray.shape[0])\n",
    "        src = np.float32([corners[0],\n",
    "                          corners[nx-1],\n",
    "                          corners[-1],\n",
    "                          corners[-nx]])\n",
    "        dst = np.float32([[offset, offset],\n",
    "                          [img_size[0]-offset, offset],\n",
    "                          [img_size[0]-offset, img_size[1]-offset], \n",
    "                          [offset, img_size[1]-offset]])\n",
    "        M = cv2.getPerspectiveTransform(src, dst)\n",
    "        warped = cv2.warpPerspective(undist, M, img_size)\n",
    "    return warped, M\n",
    "\n",
    "top_down, perspective_M = corners_unwarp(img, nx, ny, mtx, dist)\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(25, 10))\n",
    "f.tight_layout()\n",
    "\n",
    "matplotlib.rc('xtick', labelsize=35) \n",
    "matplotlib.rc('ytick', labelsize=35)\n",
    "\n",
    "ax1.imshow(img)\n",
    "ax1.set_title('Original Image: \\n', fontsize=35)\n",
    "ax2.imshow(top_down)\n",
    "ax2.set_title('Undistorted and Warped Image: \\n', fontsize=35)\n",
    "plt.subplots_adjust(left=0., right=1, top=1, bottom=0.)\n",
    "plt.savefig('resources/output_images/undistorted_and_warped.png', bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plotter(test_img, new_img, plot_title=None, n=0):\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(12.8,7.2))\n",
    "    f.tight_layout()\n",
    "    ax1.imshow(test_img)\n",
    "    ax1.set_title('Original Image:', fontsize=15)\n",
    "    ax2.imshow(new_img, cmap='gray')\n",
    "    ax2.set_title('{0}:'.format(plot_title, n+1), fontsize=15)\n",
    "    plt.xlim(0, 1280)\n",
    "    plt.ylim(720, 0)\n",
    "def pipeline(op=None):\n",
    "    test_images = glob.glob('resources/test_images/test*.jpg')\n",
    "    n = 0\n",
    "    for img in test_images:\n",
    "        img = cv2.imread(img)\n",
    "        test_img = bgr_to_rgb(img)\n",
    "        if op == 'Undistorted Image':\n",
    "            new_img = undistort(img)\n",
    "            plotter(test_img, cv2.cvtColor(new_img, cv2.COLOR_BGR2RGB), op, n)\n",
    "            matplotlib.rc('xtick', labelsize=15) \n",
    "            matplotlib.rc('ytick', labelsize=15)\n",
    "            plt.savefig('resources/output_images/undistorted.png'.format(op), bbox_inches=\"tight\")\n",
    "            break\n",
    "        if op == 'Sobel X':\n",
    "            new_img = undistort(img)\n",
    "            new_img = sobel_x(img)\n",
    "            plotter(test_img, new_img, op, n)\n",
    "            plt.savefig('resources/output_images/sobel_x.png'.format(op), bbox_inches=\"tight\")\n",
    "            break\n",
    "        n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def bgr_to_rgb(img):\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "def undistort(img):\n",
    "    mtx = dist_pickle['mtx']\n",
    "    dist = dist_pickle['dist']\n",
    "    return cv2.undistort(img, mtx, dist, None, mtx)            \n",
    "\n",
    "pipeline(op='Undistorted Image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section II: Feature Extraction and Training with a Linear SVM Classifier\n",
    "\n",
    "##### Visualize the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cars_far = glob.glob('resources/datasets/vehicles/GTI_Far/image*.png')\n",
    "cars_left = glob.glob('resources/datasets/vehicles/GTI_Left/image*.png')\n",
    "cars_middle = glob.glob('resources/datasets/vehicles/GTI_MiddleClose/image*.png')\n",
    "cars_right = glob.glob('resources/datasets/vehicles/GTI_Right/image*.png')\n",
    "cars = cars_far + cars_left + cars_middle + cars_right\n",
    "shuffle(cars)\n",
    "\n",
    "not_cars_extras = glob.glob('resources/datasets/non-vehicles/Extras/extra*.png')\n",
    "not_cars_gti = glob.glob('resources/datasets/non-vehicles/GTI/image*.png')\n",
    "not_cars = not_cars_extras + not_cars_gti\n",
    "shuffle(not_cars)\n",
    "\n",
    "def visualize_data(cars, not_cars):\n",
    "    data_dict = {}\n",
    "    data_dict[\"n_cars\"] = len(cars)\n",
    "    data_dict[\"n_not_cars\"] = len(not_cars)\n",
    "    img = mpimg.imread(cars[0])\n",
    "    data_dict[\"img_shape\"] = img.shape\n",
    "    data_dict[\"d_type\"] = img.dtype\n",
    "    return data_dict\n",
    "\n",
    "visual = visualize_data(cars, not_cars)\n",
    "\n",
    "print('Total Number of Car Images: {0}'.format(visual['n_cars']))\n",
    "print('Total Number of Non-Car Images: {0}'.format(visual['n_not_cars']))\n",
    "\n",
    "print('Image Size: {0}\\nImage Type: {1}'.format(visual['img_shape'], visual['d_type']))\n",
    "\n",
    "def random_image(cars, not_cars):\n",
    "    car_id = np.random.randint(0, len(cars))\n",
    "    not_car_id = np.random.randint(0, len(not_cars))\n",
    "    car_image = mpimg.imread(cars[car_id])\n",
    "    not_car_image = mpimg.imread(not_cars[not_car_id])\n",
    "    return car_image, not_car_image\n",
    "\n",
    "n = 0\n",
    "fig = plt.figure(figsize=(20, 10))\n",
    "while n < 10:\n",
    "    car_image, not_car_image = random_image(cars, not_cars)\n",
    "    fig.add_subplot(1, 10, n+1)\n",
    "    plt.imshow(not_car_image)\n",
    "    plt.xticks(()); plt.yticks(());    \n",
    "    plt.title('Not-Car', fontsize=20)\n",
    "    fig.add_subplot(2, 10, n+1)\n",
    "    plt.imshow(car_image)\n",
    "    plt.xticks(()); plt.yticks(());    \n",
    "    plt.title('Car', fontsize=20)\n",
    "    n += 1\n",
    "plt.savefig('resources/output_images/data_visualization.png', bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Randomly select an image for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "car_id = np.random.randint(0, len(cars))\n",
    "rand_img = cv2.imread(cars[car_id])\n",
    "rand_img = cv2.cvtColor(rand_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(rand_img);\n",
    "plt.title('Random Visualization Image:\\n', fontsize=15)\n",
    "plt.xticks(()); plt.yticks(());\n",
    "plt.savefig('resources/output_images/random_image_visualization.png', \n",
    "            bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualize histograms of color in an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "red_hist = np.histogram(rand_img[:,:,0], bins=32, range=(0, 256))\n",
    "green_hist = np.histogram(rand_img[:,:,1], bins=32, range=(0, 256))\n",
    "blue_hist = np.histogram(rand_img[:,:,1], bins=32, range=(0, 256))\n",
    "hist_features = np.concatenate((red_hist[0], green_hist[0], blue_hist[0]))\n",
    "\n",
    "bin_edges = red_hist[1] #all three bins are the same size\n",
    "bin_centers = (bin_edges[1:] + bin_edges[00:len(bin_edges) - 1])/2\n",
    "\n",
    "fig = plt.figure(figsize=(10,3));\n",
    "matplotlib.rc('xtick', labelsize=20) \n",
    "matplotlib.rc('ytick', labelsize=20)\n",
    "\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.imshow(rand_img)\n",
    "plt.title('Original Image:\\n', fontsize=30);\n",
    "\n",
    "plt.subplot(1, 4, 2)\n",
    "plt.bar(bin_centers, red_hist[0], width=3)\n",
    "plt.xlim(0, 256)\n",
    "plt.title('Red:\\n', fontsize=30);\n",
    "\n",
    "plt.subplot(1, 4, 3)\n",
    "plt.bar(bin_centers, green_hist[0], width=3)\n",
    "plt.xlim(0, 256)\n",
    "plt.title('Green:\\n', fontsize=30);\n",
    "\n",
    "plt.subplot(1, 4, 4)\n",
    "plt.bar(bin_centers, blue_hist[0], width=3)\n",
    "plt.xlim(0, 256)\n",
    "plt.title('Blue:\\n', fontsize=30);\n",
    "\n",
    "plt.subplots_adjust(left=0.5, right=2, top=1, bottom=0.)\n",
    "plt.savefig('resources/output_images/color_histograms_visualization.png', \n",
    "            bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualize the distribution of color in an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scale = max(rand_img.shape[0], rand_img.shape[1], 64) / 64\n",
    "img_small = cv2.resize(rand_img, (np.int(rand_img.shape[1] / scale), \n",
    "                                  np.int(rand_img.shape[0] / scale)), \n",
    "                                  interpolation=cv2.INTER_NEAREST)\n",
    "img_small_RGB = cv2.cvtColor(img_small, cv2.COLOR_BGR2RGB)\n",
    "img_small_HSV = cv2.cvtColor(img_small, cv2.COLOR_BGR2HSV)\n",
    "img_small_rgb = img_small_RGB / 255.\n",
    "\n",
    "pixels = img_small_RGB\n",
    "colors_rgb = img_small_rgb\n",
    "axis_labels = list('RGB')\n",
    "axis_limits = [(0,255), (0,255), (0,255)]\n",
    "\n",
    "f = plt.figure(figsize=(20,10));\n",
    "ax1 = f.add_subplot(1, 2, 1);\n",
    "f.tight_layout()\n",
    "matplotlib.rc('xtick', labelsize=40) \n",
    "matplotlib.rc('ytick', labelsize=40)\n",
    "ax1.imshow(rand_img)\n",
    "ax1.set_title('Original Image:\\n', fontsize=40);\n",
    "\n",
    "ax2 = f.add_subplot(1, 2, 2, projection='3d');\n",
    "ax2.text2D(0.15, 0.99, \"Image Color Distribution:\\n\", \n",
    "           transform=ax2.transAxes, fontsize=40)\n",
    "\n",
    "ax2.set_xlim(*axis_limits[0])\n",
    "ax2.set_ylim(*axis_limits[1])\n",
    "ax2.set_zlim(*axis_limits[2])\n",
    "\n",
    "ax2.tick_params(axis='both', which='major', labelsize=25, pad=8)\n",
    "ax2.set_xlabel(axis_labels[0], fontsize=40, labelpad=30)\n",
    "ax2.set_ylabel(axis_labels[1], fontsize=40, labelpad=30)\n",
    "ax2.set_zlabel(axis_labels[2], fontsize=40, labelpad=30)\n",
    "\n",
    "ax2.scatter(pixels[:,:,0].ravel(), pixels[:,:,1].ravel(), \n",
    "            pixels[:,:,2].ravel(), c=colors_rgb.reshape((-1, 3)), \n",
    "            edgecolors='none');\n",
    "\n",
    "plt.subplots_adjust(left=0., right=1, top=1, bottom=0.)\n",
    "plt.savefig('resources/output_images/color_distribution_visualization.png', \n",
    "            bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualize the spatial binning of color in an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "color_space = 'RGB'\n",
    "size = (8, 8)\n",
    "\n",
    "small_img = cv2.resize(rand_img, size)\n",
    "\n",
    "if color_space != 'RGB':\n",
    "    if color_space == 'HSV':\n",
    "        feature_img = cv2.cvtColor(rand_img, cv2.COLOR_RGB2HSV)\n",
    "    elif color_space == 'LUV':\n",
    "        feature_img = cv2.cvtColor(rand_img, cv2.COLOR_RGB2LUV)\n",
    "    elif color_space == 'HLS':\n",
    "        feature_img = cv2.cvtColor(rand_img, cv2.COLOR_RGB2HLS)\n",
    "    elif color_space == 'YUV':\n",
    "        feature_img = cv2.cvtColor(rand_img, cv2.COLOR_RGB2YUV)\n",
    "    elif color_space == 'YCrCb':\n",
    "        feature_img = cv2.cvtColor(rand_img, cv2.COLOR_RGB2YCrCb)\n",
    "else: \n",
    "    feature_img = np.copy(rand_img)             \n",
    "features = cv2.resize(feature_img, size).ravel() \n",
    "\n",
    "f = plt.figure(figsize=(20, 5));\n",
    "ax1 = f.add_subplot(1, 3, 1);\n",
    "f.tight_layout()\n",
    "matplotlib.rc('xtick', labelsize=30) \n",
    "matplotlib.rc('ytick', labelsize=30)\n",
    "ax1.imshow(rand_img)\n",
    "ax1.set_title('Original Image:\\n', fontsize=30);\n",
    "\n",
    "ax2 = f.add_subplot(1, 3, 2);\n",
    "ax2.imshow(small_img)\n",
    "ax2.set_title('Low Resolution Image:\\n', fontsize=30);\n",
    "\n",
    "ax3 = f.add_subplot(1, 3, 3);\n",
    "ax3.plot(features)\n",
    "ax3.set_title('Image Spatial Binning:\\n', fontsize=30);\n",
    "\n",
    "plt.subplots_adjust(left=0., right=1, top=1, bottom=0.)\n",
    "plt.savefig('resources/output_images/spatial_binning_visualization.png', \n",
    "            bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualize gradient features in an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gray = cv2.cvtColor(rand_img, cv2.COLOR_RGB2GRAY)\n",
    "sobel_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=9)\n",
    "sobel_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=9)\n",
    "gradmag = np.sqrt(sobel_x**2 + sobel_y**2)\n",
    "scale_factor = np.max(gradmag)/255 \n",
    "gradmag = (gradmag/scale_factor).astype(np.uint8) \n",
    "binary_output = np.zeros_like(gradmag)\n",
    "binary_output[(gradmag >= 50) & (gradmag <= 255)] = 1\n",
    "\n",
    "f = plt.figure(figsize=(12, 5));\n",
    "ax1 = f.add_subplot(1, 2, 1);\n",
    "f.tight_layout()\n",
    "matplotlib.rc('xtick', labelsize=20) \n",
    "matplotlib.rc('ytick', labelsize=20)\n",
    "ax1.imshow(rand_img)\n",
    "ax1.set_title('Original Image:\\n', fontsize=20);\n",
    "\n",
    "ax2 = f.add_subplot(1, 2, 2);\n",
    "ax2.imshow(binary_output, cmap='gray')\n",
    "ax2.set_title('Gradient Magnitude Image:\\n', fontsize=20);\n",
    "\n",
    "plt.subplots_adjust(left=0., right=1, top=1, bottom=0.)\n",
    "plt.savefig('resources/output_images/gradient_visualization.png', \n",
    "            bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualize HOG features in an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from skimage.feature import hog\n",
    "\n",
    "hog_img = cv2.cvtColor(rand_img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "features, hog_image = hog(hog_img, \n",
    "                          orientations=9, \n",
    "                          pixels_per_cell=(8, 8),\n",
    "                          cells_per_block=(2, 2),\n",
    "                          visualise=True,\n",
    "                          feature_vector=False)\n",
    "\n",
    "fig = plt.figure(figsize=(12, 5));\n",
    "fig.add_subplot(1, 2, 1)\n",
    "matplotlib.rc('xtick', labelsize=20) \n",
    "matplotlib.rc('ytick', labelsize=20)\n",
    "plt.imshow(rand_img)\n",
    "plt.title('Original Image:\\n', fontsize=20);\n",
    "fig.add_subplot(1, 2, 2)\n",
    "plt.imshow(hog_image, cmap='hot')\n",
    "plt.title('HOG Visualization:\\n', fontsize=20);\n",
    "plt.savefig('resources/output_images/hog_visualization.png', \n",
    "            bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Combine feature extraction methods and apply to the labeled training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_color_histogram(img, n_bins=32, bins_range=(0, 256)):\n",
    "    red_hist = np.histogram(img[:,:,0], bins=n_bins, range=bins_range)\n",
    "    green_hist = np.histogram(img[:,:,1], bins=n_bins, range=bins_range)\n",
    "    blue_hist = np.histogram(img[:,:,2], bins=n_bins, range=bins_range)\n",
    "    bin_edges = red_hist[1]\n",
    "    bin_centers = (bin_edges[1:] + bin_edges[0:len(bin_edges)-1])/2\n",
    "    hist_features = np.concatenate((red_hist[0], \n",
    "                                    green_hist[0], \n",
    "                                    blue_hist[0]))\n",
    "    return red_hist, green_hist, blue_hist, bin_centers, hist_features\n",
    "\n",
    "def get_3d_color_plot(pixels, colors_rgb,\n",
    "                      axis_labels=list(\"RGB\"),\n",
    "                      axis_limits=[(0, 255), (0, 255), (0, 255)]):\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    ax = Axes3D(fig)  \n",
    "    ax.set_xlim(*axis_limits[0])\n",
    "    ax.set_ylim(*axis_limits[1])\n",
    "    ax.set_zlim(*axis_limits[2])\n",
    "    ax.tick_params(axis='both', which='major', labelsize=14, pad=8)\n",
    "    ax.set_xlabel(axis_labels[0], fontsize=16, labelpad=16)\n",
    "    ax.set_ylabel(axis_labels[1], fontsize=16, labelpad=16)\n",
    "    ax.set_zlabel(axis_labels[2], fontsize=16, labelpad=16)\n",
    "    ax.scatter(\n",
    "        pixels[:, :, 0].ravel(),\n",
    "        pixels[:, :, 1].ravel(),\n",
    "        pixels[:, :, 2].ravel(),\n",
    "        c=colors_rgb.reshape((-1, 3)), edgecolors='none')\n",
    "    return ax\n",
    "\n",
    "def get_bin_spatial(img, color_space='RGB', size=(32, 32)):\n",
    "    if color_space != 'RGB':\n",
    "        if color_space == 'HSV':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "        elif color_space == 'LUV':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2LUV)\n",
    "        elif color_space == 'HLS':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "        elif color_space == 'YUV':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2YUV)\n",
    "        elif color_space == 'YCrCb':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2YCrCb)\n",
    "    else: feature_image = np.copy(img)             \n",
    "    features = cv2.resize(feature_image, size).ravel() \n",
    "    return features\n",
    "\n",
    "def get_gradient_features(img, sobel_kernel=9, mag_threshold=(60, 255)):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    sobel_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobel_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    gradmag = np.sqrt(sobel_x**2 + sobel_y**2)\n",
    "    scale_factor = np.max(gradmag)/255 \n",
    "    gradmag = (gradmag/scale_factor).astype(np.uint8) \n",
    "    binary_output = np.zeros_like(gradmag)\n",
    "    binary_output[(gradmag >= mag_threshold[0]) & \\\n",
    "                  (gradmag <= mag_threshold[1])] = 1\n",
    "    return binary_output\n",
    "\n",
    "def get_hog_features(img, \n",
    "                     orientation=9, \n",
    "                     pixels_per_cell=(8,8), \n",
    "                     cells_per_block=(2,2), \n",
    "                     visualization=False, \n",
    "                     feature_vector=True):\n",
    "    if visualization == True:\n",
    "        features, hog_image = hog(img, orientations=orientation, \n",
    "                                  pixels_per_cell=pixels_per_cell,\n",
    "                                  cells_per_block=cells_per_block, \n",
    "                                  transform_sqrt=False,\n",
    "                                  visualise=True, feature_vector=False)\n",
    "        return features, hog_image\n",
    "    else:\n",
    "        features = hog(img, orientations=orientation, \n",
    "                       pixels_per_cell=pixels_per_cell,\n",
    "                       cells_per_block=cells_per_block, \n",
    "                       transform_sqrt=False,\n",
    "                       visualise=False, feature_vector=feature_vector) \n",
    "        return features\n",
    "    \n",
    "def extract_features(images, color_space='RGB', \n",
    "                     spatial_size=(32,32), \n",
    "                     hist_bins=32, hist_range=(0,256),\n",
    "                     orientations=9, pixels_per_cell=(8,8),\n",
    "                     cells_per_block=(2,2), hog_channel=0,\n",
    "                     spatial_feat=True, hist_feat=True, hog_feat=True):\n",
    "    features = []\n",
    "    for file in tqdm(images):\n",
    "        file_features = []\n",
    "        img = mpimg.imread(file)\n",
    "        # apply color conversion if other than 'RGB'\n",
    "        if color_space != 'RGB':\n",
    "            if color_space == 'HSV':\n",
    "                feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "            elif color_space == 'LUV':\n",
    "                feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2LUV)\n",
    "            elif color_space == 'HLS':\n",
    "                feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "            elif color_space == 'YUV':\n",
    "                feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2YUV)\n",
    "        else: feature_image = np.copy(img)      \n",
    "        \n",
    "        if spatial_feat == True:\n",
    "            spatial_features = get_bin_spatial(feature_image, size=spatial_size)\n",
    "            file_features.append(spatial_features)\n",
    "        if hist_feat == True:\n",
    "            red_hist, green_hist, blue_hist, bin_centers, hist_features = get_color_histogram(feature_image, n_bins=hist_bins)\n",
    "            file_features.append(hist_features)\n",
    "        if hog_feat == True:\n",
    "            if hog_channel == 'ALL':\n",
    "                hog_features = []\n",
    "                for channel in range(feature_image.shape[2]):\n",
    "                    hog_features.append(get_hog_features(feature_image[:,:,channel], \n",
    "                                                         orientations, pixels_per_cell, \n",
    "                                                         cells_per_block, visualization=False,\n",
    "                                                         feature_vector=True))\n",
    "                hog_features = np.ravel(hog_features)        \n",
    "            else:\n",
    "                hog_features = get_hog_features(feature_image[:,:,hog_channel], \n",
    "                                                orientations, pixels_per_cell,\n",
    "                                                cells_per_block, visualization=False,\n",
    "                                                feature_vector=True)\n",
    "            file_features.append(hog_features)\n",
    "        features.append(np.concatenate(file_features))      \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Classify by color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "car_features = extract_features(cars, spatial_feat=True, hist_feat=True)\n",
    "not_car_features = extract_features(not_cars, spatial_feat=True, hist_feat=True)\n",
    "\n",
    "if len(car_features) > 0:\n",
    "    X = np.vstack((car_features, not_car_features)).astype(np.float64)\n",
    "    X_scaler = StandardScaler().fit(X)\n",
    "    scaled_X = X_scaler.transform(X)\n",
    "    \n",
    "    f = plt.figure(figsize=(20, 5))\n",
    "    matplotlib.rc('xtick', labelsize=30) \n",
    "    matplotlib.rc('ytick', labelsize=30)\n",
    "\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(mpimg.imread(cars[car_id]))\n",
    "    plt.title('Original Image:\\n', fontsize=30)\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(X[car_id])\n",
    "    plt.title('Raw Features:\\n', fontsize=30)\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.plot(scaled_X[car_id])\n",
    "    plt.title('Normalized Features:\\n', fontsize=30)\n",
    "    plt.savefig('resources/output_images/color_classification.png')\n",
    "\n",
    "else:\n",
    "    print('Returned empty feature vectors.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define a labels vector based on feature lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = np.hstack((np.ones(len(car_features)), np.zeros(len(not_car_features))))\n",
    "\n",
    "X = np.vstack((car_features, not_car_features)).astype(np.float64)\n",
    "X_scaler = StandardScaler().fit(X)\n",
    "scaled_X = X_scaler.transform(X)\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Shuffle and split normalized feature data into training, validation, and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rand_state = np.random.randint(0, 100)\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_X, y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=rand_state)\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train a Linear SVM classifier to classify by color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svc = LinearSVC()\n",
    "t=time.time()\n",
    "svc.fit(X_train, y_train)\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 2), 'seconds to train SVC.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check the accuracy of the color classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Test Accuracy: {0:0.4f}%'.format(svc.score(X_test, y_test)*100))\n",
    "print('  Predictions:', svc.predict(X_test[0:10]))\n",
    "print('       Labels:', y_test[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Classify by HOG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "car_features = extract_features(cars, hog_feat=True)\n",
    "not_car_features = extract_features(not_cars, hog_feat=True)\n",
    "\n",
    "if len(car_features) > 0:\n",
    "    X = np.vstack((car_features, not_car_features)).astype(np.float64)\n",
    "    X_scaler = StandardScaler().fit(X)\n",
    "    scaled_X = X_scaler.transform(X)\n",
    "    \n",
    "    f = plt.figure(figsize=(20, 5))\n",
    "    matplotlib.rc('xtick', labelsize=30) \n",
    "    matplotlib.rc('ytick', labelsize=30)\n",
    "\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(mpimg.imread(cars[car_id]))\n",
    "    plt.title('Original Image:\\n', fontsize=30)\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(X[car_id])\n",
    "    plt.title('Raw Features:\\n', fontsize=30)\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.plot(scaled_X[car_id])\n",
    "    plt.title('Normalized Features:\\n', fontsize=30)\n",
    "    plt.savefig('resources/output_images/hog_classification.png')\n",
    "\n",
    "else:\n",
    "    print('Returned empty feature vectors.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define a labels vector based on feature lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = np.hstack((np.ones(len(car_features)), np.zeros(len(not_car_features))))\n",
    "\n",
    "X = np.vstack((car_features, not_car_features)).astype(np.float64)\n",
    "X_scaler = StandardScaler().fit(X)\n",
    "scaled_X = X_scaler.transform(X)\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Shuffle and split normalized feature data into training, validation, and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rand_state = np.random.randint(0, 100)\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_X, y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=rand_state)\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train a Linear SVM classifier to classify by HOG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svc = LinearSVC()\n",
    "t=time.time()\n",
    "svc.fit(X_train, y_train)\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 2), 'seconds to train SVC.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check the accuracy of the HOG classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Test Accuracy: {0:0.4f}%'.format(svc.score(X_test, y_test)*100))\n",
    "t = time.time()\n",
    "print('  Predictions:', svc.predict(X_test[0:10]))\n",
    "print('       Labels:', y_test[0:10])\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 5), 'seconds to predict 10 labels with SVC.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section III: Search for Vehicles in Images \n",
    "\n",
    "##### Implement a sliding-window technique to filter the image for possible vehicles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def draw_boxes(img, bboxes, color=(0,0,255), thickness=6):\n",
    "    img_copy = np.copy(img)\n",
    "    for bbox in bboxes:\n",
    "        cv2.rectangle(img_copy, bbox[0], bbox[1], \n",
    "                      color, thickness)\n",
    "    return img_copy\n",
    "\n",
    "def sliding_windows(img, x_start_stop=[None,None], \n",
    "                    y_start_stop=[None,None], xy_window=(64,64),\n",
    "                    xy_overlap=(0.5,0.5)):\n",
    "    if x_start_stop[0] == None:\n",
    "        x_start_stop[0] = 0\n",
    "    if x_start_stop[1] == None:\n",
    "        x_start_stop[1] = img.shape[1]\n",
    "    if y_start_stop[0] == None:\n",
    "        y_start_stop[0] = int(img.shape[0]*0.5)\n",
    "    if y_start_stop[1] == None:\n",
    "        y_start_stop[1] = int(img.shape[0]*0.9)\n",
    "    xspan = x_start_stop[1] - x_start_stop[0]\n",
    "    yspan = y_start_stop[1] - y_start_stop[0]\n",
    "    nx_pix_per_step = np.int(xy_window[0]*(1 - xy_overlap[0]))\n",
    "    ny_pix_per_step = np.int(xy_window[1]*(1 - xy_overlap[1]))\n",
    "    nx_windows = np.int(xspan/nx_pix_per_step) - 1\n",
    "    ny_windows = np.int(yspan/ny_pix_per_step) - 1\n",
    "    window_list = []\n",
    "    for ys in range(ny_windows):\n",
    "        for xs in range(nx_windows):\n",
    "            startx = xs*nx_pix_per_step + x_start_stop[0]\n",
    "            endx = startx + xy_window[0]\n",
    "            starty = ys*ny_pix_per_step + y_start_stop[0]\n",
    "            endy = starty + xy_window[1]\n",
    "            window_list.append(((startx, starty), (endx, endy)))\n",
    "    return window_list\n",
    "\n",
    "test_img = mpimg.imread('resources/test_images/test4.jpg')\n",
    "\n",
    "windows =  sliding_windows(test_img)\n",
    "\n",
    "window_img = draw_boxes(test_img, windows)\n",
    "plt.imshow(window_img);\n",
    "matplotlib.rc('xtick', labelsize=15) \n",
    "matplotlib.rc('ytick', labelsize=15)\n",
    "plt.title('Sliding Windows Technique:\\n', fontsize=15);\n",
    "plt.savefig('resources/output_images/sliding_windows.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Apply trained classifier to search for vehicles in sliding-window images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def single_img_features(img, color_space='RGB', \n",
    "                        spatial_size=(64,64), hist_bins=64, \n",
    "                        orientations=9, pixels_per_cell=(8,8), \n",
    "                        cells_per_block=(2,2), hog_channel=0, \n",
    "                        spatial_feat=True, hist_feat=True, \n",
    "                        hog_feat=True):\n",
    "    img_features = []\n",
    "    if color_space != 'RGB':\n",
    "        if color_space == 'HSV':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "        elif color_space == 'LUV':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2LUV)\n",
    "        elif color_space == 'HLS':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "        elif color_space == 'YUV':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2YUV)\n",
    "        elif color_space == 'YCrCb':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2YCrCb)\n",
    "    else: feature_image = np.copy(img)  \n",
    "    if spatial_feat == True:\n",
    "        spatial_features = get_bin_spatial(feature_image, size=spatial_size)\n",
    "        img_features.append(spatial_features)\n",
    "    if hist_feat == True:\n",
    "        red_hist, green_hist, blue_hist, bin_centers, hist_features = get_color_histogram(feature_image, n_bins=hist_bins)\n",
    "        img_features.append(hist_features)\n",
    "    if hog_feat == True:\n",
    "        if hog_channel == 'ALL':\n",
    "            hog_features = []\n",
    "            for channel in range(feature_image.shape[2]):\n",
    "                hog_features.extend(get_hog_features(feature_image[:,:,channel], \n",
    "                                                     orientations, pixels_per_cell,\n",
    "                                                     cells_per_block, \n",
    "                                                     visualization=False,\n",
    "                                                     feature_vector=True))      \n",
    "        else:\n",
    "            hog_features = get_hog_features(feature_image[:,:,hog_channel], \n",
    "                                            orientations, pixels_per_cell,\n",
    "                                            cells_per_block, visualization=False,\n",
    "                                            feature_vector=True)\n",
    "        img_features.append(hog_features)\n",
    "    return np.concatenate(img_features)\n",
    "\n",
    "def search_windows(img, windows, svc, scaler, \n",
    "                   color_space='RGB', spatial_size=(64,64), \n",
    "                   hist_bins=64, hist_range=(0,256), orientations=9,\n",
    "                   pixels_per_cell=(8,8), cells_per_block=(2,2),\n",
    "                   hog_channel=0, spatial_feat=True,\n",
    "                   hist_feat=True, hog_feat=True):\n",
    "    on_windows = []\n",
    "    for window in windows:\n",
    "        test_img = cv2.resize(img[window[0][1]:window[1][1], window[0][0]:window[1][0]], (64, 64))      \n",
    "        features = single_img_features(test_img, color_space=color_space, \n",
    "                            spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "                            orientations=orientations, pixels_per_cell=pixels_per_cell, \n",
    "                            cells_per_block=cells_per_block, \n",
    "                            hog_channel=hog_channel, spatial_feat=spatial_feat, \n",
    "                            hist_feat=hist_feat, hog_feat=hog_feat)\n",
    "        test_features = scaler.transform(np.array(features).reshape(1, -1))\n",
    "        prediction = svc.predict(test_features)\n",
    "        if prediction == 1:\n",
    "            on_windows.append(window)\n",
    "    return on_windows\n",
    "\n",
    "color_space = 'LUV' # Can be RGB, HSV, LUV, HLS, YUV, YCrCb\n",
    "orientations = 9  # HOG orientations\n",
    "pixels_per_cell = (16,16) # HOG pixels per cell\n",
    "cells_per_block = (4,4) # HOG cells per block\n",
    "hog_channel = \"ALL\" # Can be 0, 1, 2, or \"ALL\"\n",
    "spatial_size = (16, 16) # Spatial binning dimensions\n",
    "hist_bins = 16 # Number of histogram bins\n",
    "spatial_feat = True # Spatial features on or off\n",
    "hist_feat = True # Histogram features on or off\n",
    "hog_feat = True # HOG features on or off\n",
    "y_start_stop = [None, None] # Min and max in y to search in slide_window()\n",
    "\n",
    "car_features = extract_features(cars, color_space=color_space, \n",
    "                        spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "                        orientations=orientations, pixels_per_cell=pixels_per_cell, \n",
    "                        cells_per_block=cells_per_block, \n",
    "                        hog_channel=hog_channel, spatial_feat=spatial_feat, \n",
    "                        hist_feat=hist_feat, hog_feat=hog_feat)\n",
    "not_car_features = extract_features(not_cars, color_space=color_space, \n",
    "                        spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "                        orientations=orientations, pixels_per_cell=pixels_per_cell, \n",
    "                        cells_per_block=cells_per_block, \n",
    "                        hog_channel=hog_channel, spatial_feat=spatial_feat, \n",
    "                        hist_feat=hist_feat, hog_feat=hog_feat)\n",
    "\n",
    "X = np.vstack((car_features, not_car_features)).astype(np.float64)                        \n",
    "X_scaler = StandardScaler().fit(X)\n",
    "scaled_X = X_scaler.transform(X)\n",
    "\n",
    "y = np.hstack((np.ones(len(car_features)), np.zeros(len(not_car_features))))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    scaled_X, y, test_size=0.2)\n",
    "\n",
    "print('Using:', orientations, 'orientations', pixels_per_cell,\n",
    "    'pixels per cell and', cells_per_block, 'cells per block')\n",
    "print('Feature vector length:', len(X_train[0]))\n",
    "\n",
    "svc = LinearSVC()\n",
    "t=time.time()\n",
    "svc.fit(X_train, y_train)\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 2), ' seconds to train SVC.')\n",
    "print('Test Accuracy of SVC: {0}%'.format(round(svc.score(X_test, y_test)*100, 4)))\n",
    "t=time.time()\n",
    "\n",
    "img = mpimg.imread('resources/test_images/test4.jpg')\n",
    "draw_img = np.copy(img)\n",
    "\n",
    "# Training Data extracted from .png images (scaled 0 to 1 by mpimg)\n",
    "# Search image is a .jpg (scaled 0 to 255)\n",
    "img = img.astype(np.float32)/255\n",
    "\n",
    "windows = sliding_windows(img, x_start_stop=[None, None], y_start_stop=y_start_stop, \n",
    "                    xy_window=(64, 64), xy_overlap=(0.85, 0.85))\n",
    "\n",
    "hot_windows = search_windows(img, windows, svc, X_scaler, color_space=color_space, \n",
    "                        spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "                        orientations=orientations, pixels_per_cell=pixels_per_cell, \n",
    "                        cells_per_block=cells_per_block, \n",
    "                        hog_channel=hog_channel, spatial_feat=spatial_feat, \n",
    "                        hist_feat=hist_feat, hog_feat=hog_feat)                       \n",
    "\n",
    "window_img = draw_boxes(draw_img, hot_windows)                    \n",
    "\n",
    "f = plt.figure(figsize=(20, 5))\n",
    "matplotlib.rc('xtick', labelsize=30) \n",
    "matplotlib.rc('ytick', labelsize=30)\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(img)\n",
    "plt.title('Original Image:\\n', fontsize=30);\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(window_img)\n",
    "plt.title('Bounding Boxes:\\n', fontsize=30);\n",
    "\n",
    "bbox_pickle = {}\n",
    "all_bboxes = hot_windows\n",
    "bbox_pickle[\"bboxes\"] = all_bboxes\n",
    "pickle.dump(dist_pickle, open(\"resources/bbox_pickle.p\", \"wb\"));\n",
    "\n",
    "plt.savefig('resources/output_images/positive_window_detections.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section IV: Test on a Video Stream\n",
    "\n",
    "##### Create a heat map of recurring detections frame by frame to reject outliers and follow detected vehicles.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def add_heat(heatmap, bbox_list):\n",
    "    for box in bbox_list:\n",
    "        # Add += 1 for all pixels inside each bbox\n",
    "        heatmap[box[0][1]:box[1][1], box[0][0]:box[1][0]] += 1\n",
    "    return heatmap\n",
    " \n",
    "def apply_heat_threshold(heatmap, threshold=4):\n",
    "    heatmap[heatmap <= threshold] = 0\n",
    "    return heatmap\n",
    "\n",
    "bbdict = pickle.load( open( \"resources/bbox_pickle.p\", \"rb\" ))\n",
    "all_bboxes = bbox_pickle[\"bboxes\"]\n",
    "\n",
    "img = mpimg.imread('resources/test_images/test4.jpg')\n",
    "#img = undistort(img)\n",
    "heatmap = np.zeros_like(img[:,:,0].astype(np.float))\n",
    "\n",
    "heatmap = add_heat(heatmap, all_bboxes)\n",
    "heatmap = apply_heat_threshold(heatmap)\n",
    "heatmap = np.clip(heatmap-2, 0, 255)\n",
    "\n",
    "labels = label(heatmap)\n",
    "\n",
    "#print('Cars Found: {0}'.format(labels[1]))\n",
    "\n",
    "f = plt.figure(figsize=(20, 5))\n",
    "matplotlib.rc('xtick', labelsize=30) \n",
    "matplotlib.rc('ytick', labelsize=30)\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(window_img)\n",
    "plt.title('Bounding Boxes:\\n', fontsize=30);\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(heatmap, cmap='hot')\n",
    "plt.title('Heatmap:\\n', fontsize=30);\n",
    "plt.savefig('resources/output_images/heatmap.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Estimate a bounding box for vehicles detected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def draw_labeled_bboxes(img, labels):\n",
    "    # Iterate through all detected cars\n",
    "    for car_number in range(1, labels[1]+1):\n",
    "        # Find pixels with each car_number label value\n",
    "        nonzero = (labels[0] == car_number).nonzero()\n",
    "        # Identify x and y values of those pixels\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        # Define a bounding box based on min/max x and y\n",
    "        bbox = ((np.min(nonzerox), np.min(nonzeroy)), (np.max(nonzerox), np.max(nonzeroy)))\n",
    "        # Draw the box on the image\n",
    "        cv2.rectangle(img, bbox[0], bbox[1], (0,0,255), 6)\n",
    "    # Return the image\n",
    "    return img\n",
    "\n",
    "img = mpimg.imread('resources/test_images/test4.jpg')\n",
    "draw_img = np.copy(img)\n",
    "draw_img = draw_labeled_bboxes(draw_img, labels)\n",
    "\n",
    "f = plt.figure(figsize=(20, 5))\n",
    "matplotlib.rc('xtick', labelsize=20) \n",
    "matplotlib.rc('ytick', labelsize=20)\n",
    "plt.imshow(draw_img)\n",
    "plt.title('Vehicle Bounding Boxes:\\n', fontsize=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Output results as a video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def BGRtoYUV(img):\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2YUV)\n",
    "\n",
    "orientations = 8\n",
    "pixels_per_cell = 8\n",
    "cells_per_block = 2\n",
    "\n",
    "def hog_features(channel, visualise=False):\n",
    "    if visualise == True:\n",
    "        features, hog_image = hog(channel, orientations=orientations,\n",
    "                                  pixels_per_cell=(pixels_per_cell, pixels_per_cell),\n",
    "                                  cells_per_block=(cells_per_block, cells_per_block),\n",
    "                                  transform_sqrt=False, visualise=True, feature_vector=False)\n",
    "        return hog_image\n",
    "    else:      \n",
    "        features = hog(channel, orientations=orientations,\n",
    "                       pixels_per_cell=(pixels_per_cell, pixels_per_cell),\n",
    "                       cells_per_block=(cells_per_block, cells_per_block),\n",
    "                       transform_sqrt=False, visualise=False, feature_vector=True)\n",
    "        return features\n",
    "\n",
    "def derive_features(img):\n",
    "    img = BGRtoYUV(img)\n",
    "    features_y = hog_features(img[:,:,0])\n",
    "    features_u = hog_features(img[:,:,1])\n",
    "    features_v = hog_features(img[:,:,2])\n",
    "    return np.concatenate((features_y, features_u, features_v))\n",
    "\n",
    "def search_windows(img, windows, clf, scaler):\n",
    "    # Create a list to hold the positive detections.\n",
    "    on_windows = []\n",
    "    \n",
    "    # Iterate over all the windows in the list.\n",
    "    for window in windows:\n",
    "        # Extract the window image from the original image.\n",
    "        window_img = cv2.resize(img[window[0][1]:window[1][1], window[0][0]:window[1][0]], (64, 64))\n",
    "        # Convert to the expected BGR in feature extractor.\n",
    "        window_img = cv2.cvtColor(window_img, cv2.COLOR_RGB2BGR)\n",
    "        # Extract features for the resized window image\n",
    "        features = derive_features(window_img)\n",
    "        # Normalize the extracted features.\n",
    "        features = scaler.transform(np.array(features).reshape(1, -1))\n",
    "        # Save the window if prediction is positive.\n",
    "        if clf.decision_function(features) > threshold:\n",
    "            on_windows.append(window)\n",
    "    \n",
    "    # Return the windows with positive detections.\n",
    "    return on_windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_images = []\n",
    "y = []\n",
    "\n",
    "for filename in tqdm(glob.glob('resources/datasets/vehicles/*/*.png')):\n",
    "    img = cv2.imread(filename)\n",
    "    features = derive_features(img)\n",
    "    input_images.append(features)\n",
    "    y.append(True)\n",
    "\n",
    "for filename in tqdm(glob.glob('resources/datasets/non-vehicles/*/*.png')):\n",
    "    img = cv2.imread(filename)\n",
    "    features = derive_features(img)\n",
    "    input_images.append(features)\n",
    "    y.append(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_scaler = StandardScaler().fit(input_images)\n",
    "input_images = X_scaler.transform(input_images)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(input_images, y, test_size=0.2, stratify=y, random_state=1)\n",
    "\n",
    "classifier = LinearSVC(random_state=1)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "print('Vehicle classifier trained with test accuracy: %.1f%%' % (100. * classifier.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "WINDOW_SIZES = [(64, 64), (96, 96), (128, 128)]\n",
    "WINDOW_Y_START_STOP = [(400, 500), (400, 500), (400, 500)]\n",
    "WINDOW_OVERLAP = (0.8, 0.8)\n",
    "\n",
    "# img is of RGB type\n",
    "def slide_window(img):\n",
    "    window_list = []\n",
    "    \n",
    "    for (xy_window, y_start_stop) in zip(WINDOW_SIZES, WINDOW_Y_START_STOP):\n",
    "        x_start = int(img.shape[1]/2)\n",
    "        x_stop = img.shape[1]\n",
    "        y_start = y_start_stop[0]\n",
    "        y_stop = y_start_stop[1]\n",
    "    \n",
    "        # Compute ROI.\n",
    "        xspan = x_stop - x_start\n",
    "        yspan = y_stop - y_start\n",
    "        \n",
    "        # Compute the step between successive windows.\n",
    "        nx_pix_per_step = np.int(xy_window[0] * (1. - WINDOW_OVERLAP[0]))\n",
    "        ny_pix_per_step = np.int(xy_window[1] * (1. - WINDOW_OVERLAP[1]))\n",
    "        # Compute the number of windows to generate at this size.\n",
    "        nx_windows = int(xspan/nx_pix_per_step) - 1\n",
    "        ny_windows = int(yspan/ny_pix_per_step) - 1\n",
    "        # Loop through the x and y positions to find the window coordinates.\n",
    "        for ys in range(ny_windows):\n",
    "            for xs in range(nx_windows):\n",
    "                startx = xs*nx_pix_per_step + x_start\n",
    "                endx = startx + xy_window[0]\n",
    "                starty = ys*nx_pix_per_step + y_start\n",
    "                endy = starty + xy_window[1]\n",
    "                window_list.append(((startx, starty), (endx, endy)))\n",
    "                \n",
    "    # Return the list of windows.\n",
    "    return window_list\n",
    "\n",
    "img = cv2.imread('resources/test_images/test4.jpg')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "windows = slide_window(img)\n",
    "img = draw_boxes(img, windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "threshold = 0.8\n",
    "\n",
    "def search_windows(img, windows, clf, scaler):\n",
    "    # Create a list to hold the positive detections.\n",
    "    on_windows = []\n",
    "    \n",
    "    # Iterate over all the windows in the list.\n",
    "    for window in windows:\n",
    "        # Extract the window image from the original image.\n",
    "        window_img = cv2.resize(img[window[0][1]:window[1][1], window[0][0]:window[1][0]], (64, 64))\n",
    "        # Convert to the expected BGR in feature extractor.\n",
    "        window_img = cv2.cvtColor(window_img, cv2.COLOR_RGB2BGR)\n",
    "        # Extract features for the resized window image\n",
    "        features = derive_features(window_img)\n",
    "        # Normalize the extracted features.\n",
    "        features = scaler.transform(np.array(features).reshape(1, -1))\n",
    "        # Save the window if prediction is positive.\n",
    "        if clf.decision_function(features) > threshold:\n",
    "            on_windows.append(window)\n",
    "    \n",
    "    # Return the windows with positive detections.\n",
    "    return on_windows\n",
    "\n",
    "img = cv2.imread('resources/test_images/test4.jpg')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "windows = slide_window(img)\n",
    "windows = search_windows(img, windows, classifier, X_scaler)\n",
    "img = draw_boxes(img, windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HEATMAP_THRESHOLD = 4\n",
    "\n",
    "def add_heat(heatmap, bboxes):\n",
    "    # Iterate through each bbox.\n",
    "    for bbox in bboxes:\n",
    "        # Add +1 for all pixels inside each bbox.\n",
    "        heatmap[bbox[0][1]:bbox[1][1], bbox[0][0]:bbox[1][0]] += 1\n",
    "    # Return updated heatmap.\n",
    "    return heatmap\n",
    "    \n",
    "def apply_threshold(heatmap):\n",
    "    # Zero out pixels below the threshold.\n",
    "    heatmap[heatmap <= HEATMAP_THRESHOLD] = 0\n",
    "    # Return thresholded map.\n",
    "    return heatmap\n",
    "\n",
    "img = cv2.imread('resources/test_images/test4.jpg')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "windows = slide_window(img)\n",
    "windows = search_windows(img, windows, classifier, X_scaler)\n",
    "heatmap = np.zeros_like(img[:,:,0]).astype(np.float)\n",
    "heatmap = add_heat(heatmap, windows)\n",
    "heatmap = apply_threshold(heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def draw_labeled_bboxes(img, heatmap):\n",
    "    # Generate the labels from the heat map.\n",
    "    labels = label(heatmap)\n",
    "    # Keep a list of bboxes for detected vehicles.\n",
    "    bboxes = []\n",
    "    # Iterate through all detected vehicles.\n",
    "    for vehicle in range(1, labels[1]+1):\n",
    "        # Find pixels with each vehicle label value.\n",
    "        nonzero = (labels[0] == vehicle).nonzero()\n",
    "        # Identify x and y values of those pixels.\n",
    "        nonzerox = np.array(nonzero[0])\n",
    "        nonzeroy = np.array(nonzero[1])\n",
    "        # Define a bounding box based on the min/max x and y.\n",
    "        bbox = ((np.min(nonzeroy), np.min(nonzerox)), (np.max(nonzeroy), np.max(nonzerox)))\n",
    "        bboxes.append(bbox)\n",
    "    # Draw the bounding boxes for the detected vehicles.\n",
    "    img = draw_boxes(img, bboxes)\n",
    "    # Return the annotated image.\n",
    "    return img\n",
    "\n",
    "img = cv2.imread('resources/test_images/test4.jpg')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "windows = slide_window(img)\n",
    "windows = search_windows(img, windows, classifier, X_scaler)\n",
    "heatmap = np.zeros_like(img[:,:,0]).astype(np.float)\n",
    "heatmap = add_heat(heatmap, windows)\n",
    "heatmap = apply_threshold(heatmap)\n",
    "img = draw_labeled_bboxes(img, heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frame_count = 5\n",
    "\n",
    "class VehicleDetector:\n",
    "    def __init__(self):\n",
    "        self.bboxes = []\n",
    "    \n",
    "    def add_bboxes(self, bboxes):\n",
    "        self.bboxes.append(bboxes)\n",
    "        self.bboxes = self.bboxes[-frame_count:]\n",
    "    \n",
    "    def heatmap(self):\n",
    "        heatmap = np.zeros_like(img[:,:,0]).astype(np.float)\n",
    "        for bboxes in self.bboxes:\n",
    "            add_heat(heatmap, bboxes)\n",
    "        heatmap = apply_threshold(heatmap)\n",
    "        return heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def video_pipeline(img, vehicle_detector=None):\n",
    "    if vehicle_detector is None:\n",
    "        vehicle_detector = VehicleDetector()\n",
    "    windows = slide_window(img)\n",
    "    windows = search_windows(img, windows, classifier, X_scaler)\n",
    "    vehicle_detector.add_bboxes(windows)\n",
    "    heatmap = vehicle_detector.heatmap()\n",
    "    img = draw_labeled_bboxes(img, heatmap)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "video_output = 'P5_test_video.mp4'\n",
    "clip = VideoFileClip('resources/test_videos/test_video.mp4')\n",
    "\n",
    "output_clip = clip.fl_image(video_pipeline) #color images only\n",
    "%time output_clip.write_videofile(video_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "video_output = 'P5_project_video_final.mp4'\n",
    "clip = VideoFileClip('resources/test_videos/project_video.mp4')\n",
    "\n",
    "output_clip = clip.fl_image(video_pipeline) #color images only\n",
    "%time output_clip.write_videofile(video_output, audio=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
